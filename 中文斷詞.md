
## [AI 人工智慧課程](https://http://120.108.221.55/PROFCHWU/dctai/index.php)
> NTCU DCT AI course 

> Teacher :[Professor Chih-Hung Wu](http://120.108.221.55/PROFCHWU/index.php)
> Student :[ https://medium.com/mr-wang](https://medium.com/mr-wang)

## 摘要

###  jieba中文斷詞套件

结巴中文分词
> [https://github.com/fxsjy/jieba](https://github.com/fxsjy/jieba)

交大資管開發的 結巴(jieba)斷詞台灣繁體 特化版本
> [https://github.com/APCLab/jieba-tw](https://github.com/APCLab/jieba-tw)

繁體中文詞典
https://raw.githubusercontent.com/APCLab/jieba-tw/master/jieba/dict.txt

### Word Cloud 文字雲視覺化圖形
線上版文字雲
[https://wordcloud.timdream.org/#wikipedia:Cloud](線上版文字雲
https://wordcloud.timdream.org/#wikipedia:Cloud
)



### 筆記整理




* 精確模式

句子最精確的切開，文本分析

* 全模式

句子可以成詞的詞語切出，速度快。

* 搜索引擎模式

精確模式的基礎上，將長的詞語再切分



```python
import jieba

documents = ['我來自台中教育大學', '我喜歡出國旅遊', '關心社會時事']
# 精確模式
for sentence in documents:
    seg_list = jieba.cut(sentence)
    print('/'.join(seg_list))

print('---------------')

# 全模式
for sentence in documents:
    seg_list = jieba.cut(sentence, cut_all=True)
    print('/'.join(seg_list))

print('---------------')

# 搜索引擎模式
for sentence in documents:
    seg_list = jieba.cut_for_search(sentence)
    print('/'.join(seg_list))

```

### 自定義詞典
創立 user_dict.txt 自行增加

### 找出句子關鍵字

```python
import jieba.analyse
news = '中央流行疫情指揮中心今日宣布，國內新增2例武漢肺炎（新型冠狀病毒病，COVID-19）境外移入，分別為分別自菲律賓及美國入境。指揮中心發言人莊人祥表示，案549為20多歲菲律賓籍女性，因工作於今年9月30日入境台灣，搭機前3日內檢驗陰性，入境時至集中檢疫期滿均無症狀，10月13日檢疫期滿前採檢結果為陰性，檢疫期滿後由仲介安排至隔離宿舍進行自主健康管理，並於10月22由仲介安排至醫院自費檢驗，於今日確診，目前住院隔離中。'
tags = jieba.analyse.extract_tags(news, topK=5, withWeight=True)

# 引用文字來源 ：https://news.ltn.com.tw/news/life/breakingnews/3331012

for tag in tags:
    print('word:', tag[0], 'tf-idf:', tag[1])
# 程式參考來源： https://blog.kennycoder.io/categories/Python/

```



